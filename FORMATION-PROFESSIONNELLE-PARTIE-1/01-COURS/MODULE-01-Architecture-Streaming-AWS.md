================================================================================
                            MODULE 1
              ARCHITECTURE DE STREAMING AWS
================================================================================

**Dur√©e** : 45 minutes  
**Niveau** : Fondamental  
**Objectifs** : Ma√Ætriser les concepts de base du streaming et l'architecture AWS

================================================================================
## 1. INTRODUCTION AU STREAMING DE DONNEES
================================================================================

### 1.1 Les Cinq V des M√©gadonn√©es

```mermaid
graph TB
    subgraph "Les 5 V du Big Data"
        A[Volume<br/>Quantit√© massive]
        B[Vari√©t√©<br/>Formats divers]
        C[V√©locit√©<br/>Rapidit√© temps r√©el]
        D[V√©racit√©<br/>Qualit√© donn√©es]
        E[Valeur<br/>Insights exploitables]
    end
    C -.->|Focus Streaming| F[SOLUTION<br/>Architecture<br/>Temps R√©el]
    
    style C fill:#ff6b6b
    style F fill:#51cf66
```

| V | Description | Impact Streaming |
|---|-------------|------------------|
| **Volume** | Quantit√© massive de donn√©es | Scalabilit√© horizontale requise |
| **Vari√©t√©** | Diff√©rents types et formats | Parsing et transformation flexibles |
| **V√©locit√©** | Rapidit√© g√©n√©ration/traitement | **C≈ìur du streaming (< 1s)** |
| **V√©racit√©** | Qualit√© et fiabilit√© | Validation en temps r√©el |
| **Valeur** | Insights exploitables | D√©cisions business instantan√©es |

> **Point cl√©** : Le streaming r√©pond sp√©cifiquement au d√©fi de la VELOCITE.


### 1.2 Streaming vs Traitement Batch

```mermaid
graph LR
    subgraph "STREAMING - Temps R√©el"
        A[Donn√©es<br/>arrivent] -->|< 1s| B[Traitement<br/>imm√©diat]
        B --> C[R√©sultats<br/>instantan√©s]
    end
    
    subgraph "BATCH - Par Lots"
        D[Donn√©es<br/>accumul√©es] -->|Heures/Jours| E[Traitement<br/>p√©riodique]
        E --> F[Rapports<br/>diff√©r√©s]
    end
    
    style B fill:#4ecdc4
    style C fill:#51cf66
    style E fill:#ffd93d
    style F fill:#ff6b6b
```

| Crit√®re | STREAMING (Temps R√©el) | BATCH (Par Lots) |
|---------|------------------------|------------------|
| **Traitement** | Continu d√®s arriv√©e | P√©riodique par volumes |
| **Latence** | Millisecondes √† secondes | Minutes √† heures |
| **Complexit√©** | Moyenne-√©lev√©e | Faible-moyenne |
| **Cas d'usage** | D√©tection fraude, monitoring IoT, alertes | Rapports quotidiens, analyses historiques, ETL |
| **Technos** | Kinesis, Kafka, Flink | Spark Batch, EMR, Glue |


================================================================================
2. SERVICES AWS POUR LE STREAMING
================================================================================

2.1 Amazon EC2 - Elastic Compute Cloud
---------------------------------------

ROLE : H√©berger les applications sources de donn√©es
- Serveurs web g√©n√©rant des logs
- Applications m√©tier
- Agents de collecte de donn√©es

CARACTERISTIQUES :
- Machines virtuelles configurables
- Int√©gration avec agent Kinesis
- S√©curit√© via r√¥les IAM


2.2 Amazon Kinesis Data Firehose
---------------------------------

ROLE : Service d'ingestion enti√®rement g√©r√©

CARACTERISTIQUES :
- Collecte automatique des donn√©es streaming
- Transformation via Lambda (optionnel)
- Livraison directe vers destinations (S3, OpenSearch, Redshift)
- Mise √† l'√©chelle automatique
- Latence : 60 secondes minimum

AVANTAGES :
- Aucune gestion d'infrastructure
- Configuration simplifi√©e
- Co√ªt bas√© sur l'usage


2.3 AWS Lambda
--------------

ROLE : Transformation et enrichissement serverless

CARACTERISTIQUES :
- Ex√©cution d√©clench√©e par √©v√©nements
- Pas de gestion de serveurs
- Facturation √† la milliseconde d'ex√©cution
- Int√©gration native avec Kinesis

CAS D'USAGE STREAMING :
- Enrichissement g√©olocalisation
- Parsing et validation de donn√©es
- Filtrage et agr√©gation


2.4 Amazon OpenSearch Service
------------------------------

ROLE : Indexation, recherche et analyse

CARACTERISTIQUES :
- Fork d'Elasticsearch h√©berg√© par AWS
- Indexation en temps r√©el
- Recherche full-text performante
- Dashboards de visualisation int√©gr√©s

CONCEPTS CLES :
- Index : Structure d'organisation des donn√©es
- Document : Unit√© de base (format JSON)
- Mappings : D√©finition des types de champs


2.5 Amazon Cognito
------------------

ROLE : Gestion d'identit√©s et authentification

CARACTERISTIQUES :
- Authentification utilisateurs
- Int√©gration SSO
- Contr√¥le d'acc√®s aux dashboards
- S√©paration identit√©/autorisation avec IAM


2.6 Amazon CloudWatch
---------------------

ROLE : Monitoring et observabilit√©

CARACTERISTIQUES :
- Collecte de logs et m√©triques
- Monitoring temps r√©el
- Alertes configurables
- Tra√ßabilit√© du pipeline


================================================================================
## 3. ARCHITECTURE DE REFERENCE
================================================================================

### 3.1 Workflow Complet

```mermaid
flowchart TB
    subgraph "GENERATION"
        U[üë§ Utilisateur] -->|HTTP| EC2[EC2<br/>Serveur Web]
        EC2 -->|Logs| AG[Agent<br/>Kinesis]
    end
    
    subgraph "COLLECTE & TRANSFORMATION"
        AG -->|Stream| KDF[Kinesis<br/>Data Firehose]
        KDF -->|Trigger| L[Lambda<br/>Enrichissement]
        L -->|Donn√©es<br/>enrichies| KDF
    end
    
    subgraph "STOCKAGE & ANALYSE"
        KDF -->|Index| OS[OpenSearch<br/>Service]
        OS -->|Query| OSD[OpenSearch<br/>Dashboards]
    end
    
    subgraph "SECURITE & MONITORING"
        COG[Cognito<br/>Auth] -->|Acc√®s| OSD
        CW[CloudWatch<br/>Logs] -.->|Monitor| KDF
        CW -.->|Monitor| L
        IAM[IAM<br/>Policies] -.->|Control| EC2
    end
    
    style EC2 fill:#ff9900
    style KDF fill:#8c4fff
    style L fill:#ff9900
    style OS fill:#4b8bbe
    style OSD fill:#4b8bbe
    style COG fill:#dd344c
    style CW fill:#cc2264
```


### 3.2 Flux de Donn√©es D√©taill√©

```mermaid
sequenceDiagram
    autonumber
    actor U as Utilisateur
    participant W as Web Server (EC2)
    participant A as Agent Kinesis
    participant F as Firehose
    participant L as Lambda
    participant O as OpenSearch
    participant D as Dashboards
    
    U->>W: Action (clic, navigation)
    W->>W: G√©n√®re log Apache
    W->>A: √âcrit log (IP, timestamp, page)
    A->>F: Stream continu
    F->>F: Buffer (60s / 1MB)
    F->>L: Trigger transformation
    L->>L: Enrichissement<br/>(g√©oloc, OS, browser)
    L-->>F: Donn√©es enrichies
    F->>O: Indexation JSON
    O->>D: Disponible analyse
    D->>U: Visualisation temps r√©el
```

#### D√©tail des √âtapes

| √âtape | Composant | Action | Dur√©e | Output |
|-------|-----------|--------|-------|--------|
| **1** | Utilisateur/EC2 | G√©n√©ration log Apache | < 1ms | `IP, timestamp, page, user-agent` |
| **2** | Agent Kinesis | Collecte continu| < 100ms | Stream vers Firehose |
| **3** | Firehose | Buffer & trigger Lambda | 60s | Batch de records |
| **4** | Lambda | Enrichissement donn√©es | 100-500ms | JSON enrichi |
| **5** | OpenSearch | Indexation | < 1s | Document index√© |
| **6** | Dashboards | Visualisation | Instantan√© | Graphiques temps r√©el |


### 3.3 Composants de S√©curit√©

```mermaid
graph TD
    subgraph "Couches de S√©curit√©"
        A[IAM<br/>Autorisations] --> B[Cognito<br/>Authentification]
        B --> C[Encryption<br/>TLS/SSL + KMS]
        C --> D[CloudTrail<br/>Audit]
    end
    
    A -.->|R√¥les| E[EC2]
    A -.->|R√¥les| F[Lambda]
    A -.->|R√¥les| G[Firehose]
    B -.->|Auth| H[Dashboards]
    C -.->|Protect| I[Data in Transit]
    C -.->|Protect| J[Data at Rest]
    
    style A fill:#dd344c
    style B fill:#ff9900
    style C fill:#8c4fff
    style D fill:#4b8bbe
```

#### Tableau de S√©curit√©

| Composant | R√¥le | Technologies | Best Practice |
|-----------|------|--------------|---------------|
| **IAM** | Autorisations | R√¥les, Politiques | Moindre privil√®ge |
| **Cognito** | Authentification | User Pools, MFA | Rotation passwords |
| **KMS** | Encryption cl√©s | CMK, Auto-rotation | Key policies strictes |
| **CloudTrail** | Audit | Logs API | Stockage S3 s√©curis√© |
| **VPC** | Isolation r√©seau | Security Groups | Principe zero-trust |


================================================================================
4. CAS D'USAGE METIER
================================================================================

4.1 Analyse de Logs Web
-----------------------

PROBLEMATIQUE :
Comprendre le comportement des visiteurs sans scripts tiers bloqu√©s

SOLUTION :
- Logs serveur Apache (donn√©es fiables)
- Enrichissement g√©olocalisation/appareil
- Visualisation temps r√©el des tendances

BENEFICES :
- Donn√©es pr√©cises et compl√®tes
- Conformit√© RGPD (donn√©es first-party)
- Analyse comportementale avanc√©e


4.2 D√©tection d'Anomalies IoT
------------------------------

FLUX :
Capteurs IoT ‚Üí Kinesis Streams ‚Üí Lambda (d√©tection) ‚Üí Alertes SNS
                              ‚Üí Firehose ‚Üí S3 (archivage)


4.3 Personnalisation E-commerce
--------------------------------

FLUX :
Clics utilisateur ‚Üí Kinesis ‚Üí Lambda (calcul recommandations)
                            ‚Üí DynamoDB (profil utilisateur)
                            ‚Üí OpenSearch (historique recherche)


================================================================================
5. CONCEPTS CLES A RETENIR
================================================================================

PIPELINE DE STREAMING
- Architecture orient√©e √©v√©nements
- Traitement continu et automatis√©
- Scalabilit√© horizontale

SERVICES GERES vs AUTO-HEBERGES
- Firehose : enti√®rement g√©r√©, simple
- Kinesis Streams : plus de contr√¥le, n√©cessite consommateurs

TRANSFORMATION EN VOL
- Lambda pour enrichissement temps r√©el
- √âvite le stockage de donn√©es brutes puis traitement
- R√©duit latence et co√ªts de stockage

OBSERVABILITE
- CloudWatch essentiel pour production
- Logs structur√©s pour debugging
- M√©triques pour optimisation

SECURITE PAR CONCEPTION
- IAM pour autorisation
- Cognito pour authentification
- Encryption bout en bout


================================================================================
6. EXERCICES DE REFLEXION
================================================================================

1. Pourquoi utiliser Kinesis Firehose plut√¥t que stocker directement dans S3 
   depuis EC2 ?

2. Quels sont les avantages de transformer les donn√©es avec Lambda avant 
   indexation dans OpenSearch ?

3. Dans quels cas pr√©f√©reriez-vous Kinesis Data Streams √† Kinesis Data Firehose ?

4. Comment assurer la haute disponibilit√© de cette architecture ?

5. Quelles m√©triques CloudWatch sont critiques pour surveiller ce pipeline ?


================================================================================
POINTS CLES DU MODULE
================================================================================

- Le streaming r√©pond aux besoins de traitement temps r√©el (v√©locit√©)
- AWS offre des services manag√©s pour chaque √©tape du pipeline
- Architecture standard : Collecte ‚Üí Transformation ‚Üí Indexation ‚Üí Visualisation
- Lambda permet l'enrichissement serverless des donn√©es en vol
- OpenSearch indexe pour recherche et analyse rapides
- S√©curit√© int√©gr√©e via IAM, Cognito et encryption
- CloudWatch assure l'observabilit√© du syst√®me


================================================================================
RESSOURCES COMPLEMENTAIRES
================================================================================

- AWS Kinesis Documentation
- OpenSearch Service Best Practices
- Lambda Streaming Use Cases
- CloudWatch Logs Insights

================================================================================

